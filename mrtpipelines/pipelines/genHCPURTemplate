#!/usr/bin/env python3
""" genHCPURTemplate

Python command line interface for MRTrix3 multi-shell multi-tissue
constrained spherical deconvolution tractography pipeline with Dhollander
response function

"""
def get_parser():
    """
    Argument parser
    """
    from argparse import ArgumentParser, RawTextHelpFormatter

    parser = ArgumentParser(description="Pipeline to generate MRTrix3 "
                                        "multi-shell multi-tissue CSD "
                                        "tractography with Dhollander "
                                        "response",
                            formatter_class=RawTextHelpFormatter)

    # Version option
    parser.add_argument("-v", "--version", dest="version",
                        action="version", version="1.0.1")

    # Required arguments
    g_req = parser.add_argument_group("Required arguments")
    g_req.add_argument("bids_dir", help="Directory with input dataset, "
                                        "formatted according to the BIDS "
                                        "standard.")
    g_req.add_argument('participant_label', help="A file containing label(s) "
                                                 "of participant(s) to perform "
                                                 "pipeline execution on")

    # Optional arguments
    g_opt = parser.add_argument_group("Optional arguments")
    g_opt.add_argument("-s", "--select", dest="select", default=100000,
                                         help="Number of streamlines to "
                                              "generate for each subject. "
                                              "Defaults 100,000 streamlines")
    g_opt.add_argument("-w", "--work_dir", dest="work_dir",
                                           help="Work directory. Defaults to "
                                            "<bids_dir>/derivatives/MRtrix/work")
    g_opt.add_argument("-o", "--out_dir", dest="out_dir",
                                          help="Output directory. Defaults to "
                                           "<bids_dir>/derivatives/MRtrix")
    g_opt.add_argument("-n", "--nthreads", dest="nthreads", default=1,
                                           help="The number of threads to use "
                                           "for pipeline execution where "
                                           "applicable.")

    return parser


def main():
    """
    Entry point of coide
    """
    import os
    import os.path as op

    from bids.grabbids import BIDSLayout
    # MRTrix subject tractography generation workflow
    from nipype import config, logging
    from nipype.pipeline import engine as pe

    from mrtpipelines.interfaces import io
    from mrtpipelines.workflows.tractography import (population_wf, preproc_wf,
                                                     tractography_wf)

    args = get_parser().parse_args()

    # Required inputs
    bids_dir = args.bids_dir
    deriv_dir = op.join(op.abspath(bids_dir), "derivatives")
    subjids = args.participant_label
    nfibers = int(args.select)
    nthreads = int(args.nthreads)

    # Set work & crash directories
    if args.work_dir:
        work_dir = op.abspath(args.work_dir)
        crash_dir = op.join(op.abspath(args.work_dir), "crash")
    else:
        work_dir = op.join(bids_dir, "derivatives/MRtrix/work")
        crash_dir = op.join(op.abspath(bids_dir, "derivatives/crash"))

    if not op.exists(work_dir):
        os.makedirs(work_dir)
    if not op.exists(crash_dir):
        os.makedirs(crash_dir)

    if args.out_dir:
        out_dir = op.abspath(args.out_dir)
    else:
        out_dir = op.join(deriv_dir, 'MRtrix')

    config.update_config({'logging': {'log_directory': work_dir,
                                      'log_to_file': True,
                                      },
                          'execution': {'crashdump_dir': crash_dir,
                                        'crashfile_format': 'txt'
                                        }})
    logging.update_logging(config)

    # getSubj
    Subjid, noSubj = io.getSubj(subjids, work_dir)

    # Create necessary nodes not part of existing workflows
    # BIDSDataGrabber
    layout = BIDSLayout(bids_dir)
    BIDSDataGrabber = io.getBIDS(layout=layout, wdir=work_dir)

    # MRTrix preprocessing workflow
    hcp_preproc_wf = preproc_wf.hcp_preproc_wf(wdir=work_dir,
                                                    nthreads=nthreads)

    # MRTrix population template workflow
    template_proc_wf = population_wf.pop_template_wf(wdir=work_dir,
                                                nthreads=nthreads)

    # MRTrix tractography preperation workflow
    prepDhollTract_wf = preproc_wf.prepDhollTract_wf(wdir=work_dir,
                                                 nthreads=nthreads)

    # MRTrix template tractography generation workflow
    genTemplate_wf = tractography_wf.genTemplate_wf(wdir=work_dir,
                                                    nthreads=nthreads)

    # Template datasink
    templateSink = io.templateSink(out_dir, wdir=work_dir)

    # Rename nodes for subject sinking
    renameWarp1 = io.renameFile(file_name='space-Template_warp',
                                node_name='renameWarp1', wdir=work_dir)

    renameWarp2 = io.renameFile(file_name='space-dwi_warp',
                                node_name='renameWarp2', wdir=work_dir)

    # Subject datasink
    subjSink = io.subjSink(out_dir, wdir=work_dir)
    regex_sub = [('_subjid_sub-[0-9]*', ''),
                ('_renameTract[0-9]*', ''),
                ('_renameWarp[0-9]*', '')]
    subjSink.inputs.regexp_substitutions = regex_sub

    # Pipeline creation (join nodes and workflows)
    pl = pe.Workflow(name='genHCPTemplate')
    pl.base_dir = work_dir

    pl.connect([
                # Input
                (Subjid, BIDSDataGrabber, [
                    ('subjid', 'subjid')]),
                (BIDSDataGrabber, hcp_preproc_wf, [
                    ('nifti', 'dataConvert.in_file'),
                    ('bdata', 'dataConvert.grad_fsl'),
                    ('bdata', 'dwi2response.grad_fsl'),
                    ('mask', 'maskConvert.in_file')]),

                # Workflows
                (hcp_preproc_wf, template_proc_wf, [
                    ('dwi2response.gm_file', 'avgResponse_gm.in_files'),
                    ('dwi2response.wm_file', 'avgResponse_wm.in_files'),
                    ('dwi2response.csf_file', 'avgResponse_csf.in_files'),
                    ('dataConvert.out_file', 'dwi2fod.in_file'),
                    ('maskConvert.out_file', 'mtnormalise.mask'),
                    ('maskConvert.out_file', 'copyMask.in_file')]),
                # (template_proc_wf, prepDhollTract_wf, [
                #     ('dwi2fod.wm_odf', 'MRRegister.in_file'),
                #     ('population_template.out_file', 'MRRegister.ref_file'),
                #     ('dwi2fod.wm_odf', 'FODTransform.in_file')]),
                # (hcp_preproc_wf, prepDhollTract_wf, [
                #     ('dwi2mask.out_file', 'MRRegister.mask1'),
                #     ('dwi2mask.out_file', 'MaskTransform.in_file')]),
                # (prepDhollTract_wf, genTemplate_wf, [
                #     ('tcksift.out_file', 'tempConvert1.in_file')]),

                # File rename
                # (Subjid, renameWarp1, [
                #     ('subjid', 'subjid')]),
                # (prepDhollTract_wf, renameWarp1, [
                #     ('WarpSelect1.out', 'in_file')]),
                # (Subjid, renameWarp2, [
                #     ('subjid', 'subjid')]),
                # (prepDhollTract_wf, renameWarp2, [
                #     ('WarpSelect2.out', 'in_file')]),

                # Output
                (template_proc_wf, templateSink, [
                    ('population_template.out_file', 'response.@template'),
                    ('avgResponse_csf.out_file', 'response.@csf'),
                    ('avgResponse_gm.out_file', 'response.@gm'),
                    ('avgResponse_wm.out_file', 'response.@wm')])
                # (genTemplate_wf, templateSink, [
                #     ('tempConvert3.out_file', 'tractography.@tract')]),
                # (Subjid, subjSink, [
                #     ('subjid', 'container')]),
                # (renameWarp1, subjSink, [
                #     ('out_file', 'transform.@warp1')]),
                # (renameWarp2, subjSink, [
                #     ('out_file', 'transform.@warp2')])
            ])

    pl.write_graph(graph2use='flat', format='svg', simple_form=False)
    pl.write_graph(graph2use='colored', format='svg')

    if nthreads >= 4:
        pl.run(plugin='MultiProc', plugin_args={'n_procs': nthreads})
    else:
        pl.run(plugin='Linear')


if __name__ == '__main__':
    main()
