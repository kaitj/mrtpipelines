#!/usr/bin/env python
""" tractScalar

Python command line interface for tracking scalar information for tractography
streamlines via Mrtrix3

"""
def get_parser():
    """
    Argument Parser
    """
    from argparse import ArgumentParser, RawTextHelpFormatter
    from mrtpipelines._version import __version__

    parser = ArgumentParser(description=("Tracks scalar information for "
                                         "streamlines and returns text file"),
                            formatter_class=RawTextHelpFormatter)

    # Version option
    parser.add_argument("--version", action="version", version=__version__)

    # Required arguments
    g_req = parser.add_argument_group("Required arguments")
    g_req.add_argument("bids_dir", help=("Directory with input dataset, "
                                         "formatted according to BIDS "
                                         "standard"))
    g_req.add_argument("participant_label", help=("Participant id to perform "
                                                  "scalar tracking"))
    g_req.add_argument("scalar", help="Scalar to be tracked")

    # Optional arguments
    g_opt = parser.add_argument_group("Optional arguments")
    g_opt.add_argument("-o", "--out_dir", dest="out_dir",
                       help=("Ouptut directory. Defaults to "
                             "<bids_dir>/mrtpipelines"))
    g_opt.add_argument("-w", "--work_dir", dest="work_dir",
                       help=("Work directory. Defaults to "
                             "<bids_dir>/work"))
    g_opt.add_argument("-v", "--verbose", action="count", default=0,
                       help="verbosity of tool")
    g_opt.add_argument("-n", "--nthreads", dest="nthreads", default=1,
                       help="The number of threads to use, if applicable")

    return parser

def main():
    """
    Entry point of code
    """
    import os
    import os.path as op
    from datetime import datetime

    from bids.grabbids import BIDSLayout

    from nipype.pipeline import engine as pe
    from nipype import config, logging

    from mrtpipelines.interfaces import io, tractography

    args = get_parser().parse_args()
    # Required inputs
    bids_dir = args.bids_dir
    subjid = args.participant_label
    scalar = args.scalar

    # Optional inputs
    nthreads = int(args.nthreads)

    # Get timestamp to distinguish work dirs for overwrite problem
    now = datetime.now()
    current_time = now.strftime("%Y-%m-%d_%Hh%Mm%Ss")

    # Set work & crash directories
    if args.work_dir:
        work_dir = op.join(op.join(op.realpath(args.work_dir), current_time),
            subjid)
        crash_dir = op.join(op.join(op.join(op.realpath(args.work_dir),
            current_time), subjid), "crash")
    else:
        work_dir = op.join(op.join(op.join(bids_dir, "work"), current_time),
            subjid)
        crash_dir = op.join(op.join(op.join(op.join(op.realpath(bids_dir),
                    "work"), current_time), subjid), "crash")

    if not op.exists(work_dir):
        os.makedirs(work_dir)
    if not op.exists(crash_dir):
        os.makedirs(crash_dir)

    # Set output directory
    if args.out_dir:
        out_dir = op.realpath(args.out_dir)
    else:
        out_dir = op.join(op.join("mrtpipelines", subjid), "dti")

    config.update_config({"logging": {"log_directory": work_dir,
                                      "log_to_file": True,
                                      },
                          "execution": {"crashdump_dir": crash_dir,
                                        "crashfile_format": "txt",
                                        "hash_method": "content"
                                        }})
    logging.update_logging(config)

    # Grab necessary files
    layout = BIDSLayout(bids_dir)
    BIDSScalarGrabber = io.getScalarData(layout=layout, subj=subjid,
                                         scalar=scalar, wdir=work_dir,
                                         nthreads=nthreads)

    tckSample = tractography.tckSample(wdir=work_dir, nthreads=nthreads)

    writeScalar = tractography.writeScalar(wdir=work_dir)

    filename = "space-Template_model-DTI_%s" % scalar
    renameScalar = io.renameFile(file_name=filename,
                                 node_name="renameScalar", wdir=work_dir,
                                 nthreads=nthreads)

    subjSink = io.subjSink(out_dir, wdir=work_dir, nthreads=nthreads)
    regex_sub = [('_subjid_sub-[0-9]*', ''),
                 ('_renameScalar[0-9]*', '')]
    subjSink.inputs.regexp_substitutions = regex_sub

    # Workflow creation
    pl = pe.Workflow(name='tractScalar')
    pl.base_dir = work_dir

    pl.connect([
        # Input
        (BIDSScalarGrabber, tckSample, [('tract', 'in_file'),
                                        ('scalar', 'in_image')]),
        # Processing
        (tckSample, writeScalar, [('out_file', 'in_file')]),
        # File rename
        (BIDSScalarGrabber, renameScalar, [('subjid', 'subjid')]),
        (writeScalar, renameScalar, [('out_file', 'in_file')]),
        # # Output
        (BIDSScalarGrabber, subjSink, [('subjid', 'container')]),
        (renameScalar, subjSink, [('out_file', 'dti.@scalar')])
    ])

    pl.write_graph(graph2use='flat', format='svg', simple_form=False)
    pl.write_graph(graph2use='colored', format='svg')

    if nthreads > 1:
        pl.run(plugin='MultiProc', plugin_args={'n_procs': 1})
    else:
        pl.run(plugin='Linear')


if __name__ == '__main__':
    main()
